{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Web scraping template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from re import sub\n",
    "from decimal import Decimal\n",
    "import io\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# functions to clean data\n",
    "def to_num(price):\n",
    "    '''\n",
    "    1. Input price-formatted values (e.g. £ 10,000,000)\n",
    "    2. Normalize value to plain numeric value (e.g. 10000000)\n",
    "    '''\n",
    "    value = Decimal(sub(r'[^\\d.]', '', price))\n",
    "    return float(value)\n",
    "\n",
    "def is_skipped(price):\n",
    "    '''\n",
    "    1. Detect price labels that are not actual prices\n",
    "       (e.g. \"POA\")\n",
    "    2. Return false if no price value is applicable\n",
    "    '''\n",
    "    for i in range(len(price)):\n",
    "        if(price[i] != '£' and price[i] != ','\n",
    "           and (not price[i].isdigit())):\n",
    "              return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# base link to scrape ads across London\n",
    "url = '{{ENTER_WEBSITE_URL_OF_SEARCH_REQUEST_HERE}}'\n",
    "\n",
    "map = {}\n",
    "id = 0\n",
    "\n",
    "# define how many pages to scrape for \"London\"\n",
    "max_pages = 4\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for p in range(max_pages):\n",
    "    \n",
    "    \n",
    "    cur_url = url + str(p + 1)\n",
    "\n",
    "    print(\"Scraping page: %d\" % (p + 1))\n",
    "\n",
    "    html_text = requests.get(cur_url).text\n",
    "    soup = BeautifulSoup(html_text, 'lxml')\n",
    "\n",
    "    ads = soup.find_all('div', class_ = '{{HTML CLASS TO TARGET AD}}')\n",
    "    #print(len(ads))\n",
    "    \n",
    "    # comment this logic\n",
    "    page_nav = soup.find_all('a', class_ = '{{HTML CLASS TO TARGET LINK IN NEXT BUTTON}}')\n",
    "\n",
    "    if(len(page_nav) == 0):\n",
    "        print(\"max page number: %d\" % (p))\n",
    "        end = time.time()\n",
    "        print(end - start)\n",
    "        break\n",
    "\n",
    "    for k in range(len(ads)):\n",
    "        \n",
    "        ad = ads[k]\n",
    "        \n",
    "        id += 1\n",
    "        map[id] = {}\n",
    "\n",
    "        #find section for address\n",
    "        address = ad.find('p', class_ = '{{HTML CLASS TO TARGET ADDRESS}}').text\n",
    "\n",
    "        #find price information\n",
    "        price = ad.find('p', class_ = 'css-6v9gpl-Text eczcs4p0').text\n",
    "\n",
    "        # drop if price section does not contain a real price value\n",
    "        if(is_skipped(price)): continue\n",
    "\n",
    "        #find public transport information\n",
    "        transport_section = ad.find('div', class_ = '{{HTML CLASS}}')\n",
    "        transport_type = ad.find_all('span', class_ = '{{HTML CLASS}}')\n",
    "        transport_information = transport_section.find_all('p', class_ = '{{HTML CLASS}}')\n",
    "\n",
    "        #assign address\n",
    "        map[id][\"address\"] = address     \n",
    "\n",
    "        #assign price\n",
    "        map[id][\"price\"] = to_num(price)\n",
    "\n",
    "        # create dicts for public transport information\n",
    "        map[id][\"distance\"] = []\n",
    "        map[id][\"station\"] = []\n",
    "        map[id][\"transport_type\"] = []\n",
    "\n",
    "        for i in range(len(transport_information)):\n",
    "            s = transport_information[i].text\n",
    "            x = s.split(' miles ')\n",
    "            map[id][\"distance\"].append(float(x[0]))\n",
    "            map[id][\"station\"].append(x[1])\n",
    "            map[id][\"transport_type\"].append(transport_type[i]['testid'])\n",
    "        \n",
    "\n",
    "print(\"Scraping task finished\")\n",
    "end = time.time()\n",
    "print(str(round(end - start, 2)) + 'sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform dictionary into list of lists**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to dict to list\n",
    "result = []\n",
    "cur_row = 0\n",
    "\n",
    "for id in map.keys():\n",
    "    cur_price = map[cur_id][\"price\"]\n",
    "    cur_address = map[cur_id][\"address\"]\n",
    "    for idx in range(len(map[id][\"distance\"])):\n",
    "        result.append([])\n",
    "        result[cur_row].append(int(cur_id))\n",
    "        result[cur_row].append(float(cur_price))\n",
    "        result[cur_row].append(str(cur_address))\n",
    "        result[cur_row].append(float(map[id][\"distance\"][idx]))\n",
    "        result[cur_row].append(str(map[id][\"station\"][idx]))\n",
    "        result[cur_row].append(str(map[id][\"transport_type\"][idx]))\n",
    "\n",
    "        cur_row += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform to DF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result, columns = [\"ad_id\", \"price\",\"address\", \"distance\",\n",
    "                                     \"station\", \"transport_type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Export as CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'test.csv'\n",
    "df.to_csv(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
